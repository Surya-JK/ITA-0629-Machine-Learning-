import numpy as np
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.datasets import make_blobs

# 1. Generate Synthetic Data (Two distinct clusters)
X, y_true = make_blobs(n_samples=300, centers=2, cluster_std=0.60, random_state=0)

# 2. Apply EM Algorithm (Gaussian Mixture Model)
gmm = GaussianMixture(n_components=2, random_state=42)
gmm.fit(X)

# 3. Predict the cluster labels
labels = gmm.predict(X)

# 4. Visualize
plt.figure(figsize=(8, 5))
plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis')
plt.title('Expectation-Maximization (GMM) Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()

# Display Converged Log-Likelihood
print(f"Converged: {gmm.converged_}")
print(f"Number of iterations: {gmm.n_iter_}")
print(f"Means of clusters:\n {gmm.means_}")
